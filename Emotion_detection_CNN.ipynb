{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyjaoV9ssG3c",
    "outputId": "a6fbdcbd-e759-4e7d-84f4-5c7131885e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-656b6e677152>:19: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Activation, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import  RandomNormal\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.test.is_gpu_available(cuda_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7_R9kclshns"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/Emotion_detection/fer2013.csv')\n",
    "\n",
    "emotions_names = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "data['emotion_name'] = data['emotion'].map(emotions_names)\n",
    "\n",
    "pixels_values = data.pixels.str.split(\" \").tolist()\n",
    "pixels_values = pd.DataFrame(pixels_values, dtype=int)\n",
    "images = pixels_values.values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "test_idx_start = 32298\n",
    "images_test = images[test_idx_start:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Standarizing images\n",
    "each_pixel_mean = images.mean(axis=0)\n",
    "each_pixel_std = np.std(images, axis=0)\n",
    "images = np.divide(np.subtract(images,each_pixel_mean), each_pixel_std)\n",
    "\n",
    "\n",
    "image_pixels = images.shape[1]\n",
    "image_width = image_height = np.ceil(np.sqrt(image_pixels)).astype(np.uint8)\n",
    "labels_flat = data[\"emotion\"].values.ravel()\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "\n",
    "\n",
    "# Function for creating zero/ones matrix indicating image label\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[[index_offset + labels_dense.ravel()]] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bloo6uICuGTI"
   },
   "outputs": [],
   "source": [
    "images = images.reshape(images.shape[0], 48, 48, 1)\n",
    "images = images.astype('float32')\n",
    "\n",
    "# Splitting images and labels into training, validation and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, shuffle = False)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_9dXZg4uL5p",
    "outputId": "077d508f-5976-4646-d921-5347fdeb67eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 23, 23, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 23, 23, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 23, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 5, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 14343     \n",
      "=================================================================\n",
      "Total params: 3,333,703\n",
      "Trainable params: 3,332,679\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Constructing CNN structure\n",
    "model = Sequential()\n",
    "\n",
    "# 1st convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', input_shape=(48,48,1), bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', input_shape=(48,48,1), bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "          \n",
    "# 5th convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 7th convolution layer\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same', bias_initializer=RandomNormal(stddev=1), kernel_initializer=RandomNormal(stddev=1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "# Fully connected layers\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(labels_count, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gZVNBAnuVk-",
    "outputId": "6fc251fb-46b8-4912-9c40-704f86a9022e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.8688 - accuracy: 0.2284 - val_loss: 2.0518 - val_accuracy: 0.2452\n",
      "Epoch 2/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.8160 - accuracy: 0.2444 - val_loss: 2.2555 - val_accuracy: 0.2486\n",
      "Epoch 3/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.8046 - accuracy: 0.2516 - val_loss: 2.2754 - val_accuracy: 0.2585\n",
      "Epoch 4/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.7918 - accuracy: 0.2575 - val_loss: 1.8856 - val_accuracy: 0.2759\n",
      "Epoch 5/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.7770 - accuracy: 0.2633 - val_loss: 1.9510 - val_accuracy: 0.2898\n",
      "Epoch 6/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.7632 - accuracy: 0.2712 - val_loss: 2.5547 - val_accuracy: 0.3019\n",
      "Epoch 7/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.7448 - accuracy: 0.2804 - val_loss: 2.0810 - val_accuracy: 0.3121\n",
      "Epoch 8/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.7258 - accuracy: 0.2871 - val_loss: 1.9484 - val_accuracy: 0.3276\n",
      "Epoch 9/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.7072 - accuracy: 0.2992 - val_loss: 1.8599 - val_accuracy: 0.3424\n",
      "Epoch 10/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.6897 - accuracy: 0.3081 - val_loss: 2.0404 - val_accuracy: 0.3560\n",
      "Epoch 11/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.6695 - accuracy: 0.3188 - val_loss: 2.1925 - val_accuracy: 0.3659\n",
      "Epoch 12/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.6627 - accuracy: 0.3282 - val_loss: 1.6175 - val_accuracy: 0.3923\n",
      "Epoch 13/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.6400 - accuracy: 0.3467 - val_loss: 1.6181 - val_accuracy: 0.4050\n",
      "Epoch 14/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.6287 - accuracy: 0.3493 - val_loss: 1.5399 - val_accuracy: 0.4232\n",
      "Epoch 15/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.6136 - accuracy: 0.3650 - val_loss: 1.5652 - val_accuracy: 0.4406\n",
      "Epoch 16/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.5980 - accuracy: 0.3719 - val_loss: 1.4665 - val_accuracy: 0.4421\n",
      "Epoch 17/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.5811 - accuracy: 0.3821 - val_loss: 1.4812 - val_accuracy: 0.4471\n",
      "Epoch 18/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.5600 - accuracy: 0.3884 - val_loss: 1.4405 - val_accuracy: 0.4545\n",
      "Epoch 19/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.5489 - accuracy: 0.3976 - val_loss: 1.4306 - val_accuracy: 0.4659\n",
      "Epoch 20/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.5356 - accuracy: 0.4047 - val_loss: 1.3904 - val_accuracy: 0.4783\n",
      "Epoch 21/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.5174 - accuracy: 0.4129 - val_loss: 1.3960 - val_accuracy: 0.4765\n",
      "Epoch 22/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4995 - accuracy: 0.4183 - val_loss: 1.4207 - val_accuracy: 0.4783\n",
      "Epoch 23/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4890 - accuracy: 0.4242 - val_loss: 1.3954 - val_accuracy: 0.4641\n",
      "Epoch 24/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4761 - accuracy: 0.4311 - val_loss: 1.3261 - val_accuracy: 0.4991\n",
      "Epoch 25/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4630 - accuracy: 0.4380 - val_loss: 1.3943 - val_accuracy: 0.4904\n",
      "Epoch 26/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4467 - accuracy: 0.4408 - val_loss: 1.4671 - val_accuracy: 0.4901\n",
      "Epoch 27/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4318 - accuracy: 0.4457 - val_loss: 1.4190 - val_accuracy: 0.5043\n",
      "Epoch 28/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4236 - accuracy: 0.4525 - val_loss: 1.2906 - val_accuracy: 0.5133\n",
      "Epoch 29/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4070 - accuracy: 0.4601 - val_loss: 1.2729 - val_accuracy: 0.5152\n",
      "Epoch 30/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.4007 - accuracy: 0.4600 - val_loss: 1.2717 - val_accuracy: 0.5254\n",
      "Epoch 31/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.3803 - accuracy: 0.4677 - val_loss: 1.3389 - val_accuracy: 0.5248\n",
      "Epoch 32/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.3713 - accuracy: 0.4729 - val_loss: 1.2641 - val_accuracy: 0.5241\n",
      "Epoch 33/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.3563 - accuracy: 0.4767 - val_loss: 1.2841 - val_accuracy: 0.5310\n",
      "Epoch 34/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.3505 - accuracy: 0.4825 - val_loss: 1.2720 - val_accuracy: 0.5241\n",
      "Epoch 35/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.3394 - accuracy: 0.4821 - val_loss: 1.2892 - val_accuracy: 0.5458\n",
      "Epoch 36/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.3376 - accuracy: 0.4877 - val_loss: 1.2505 - val_accuracy: 0.5356\n",
      "Epoch 37/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.3162 - accuracy: 0.4934 - val_loss: 1.2482 - val_accuracy: 0.5461\n",
      "Epoch 38/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.3176 - accuracy: 0.4962 - val_loss: 1.2482 - val_accuracy: 0.5477\n",
      "Epoch 39/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.3041 - accuracy: 0.4999 - val_loss: 1.2210 - val_accuracy: 0.5576\n",
      "Epoch 40/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2956 - accuracy: 0.5084 - val_loss: 1.1957 - val_accuracy: 0.5526\n",
      "Epoch 41/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2850 - accuracy: 0.5066 - val_loss: 1.2109 - val_accuracy: 0.5489\n",
      "Epoch 42/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2840 - accuracy: 0.5106 - val_loss: 1.1967 - val_accuracy: 0.5533\n",
      "Epoch 43/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2763 - accuracy: 0.5130 - val_loss: 1.2091 - val_accuracy: 0.5560\n",
      "Epoch 44/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2659 - accuracy: 0.5152 - val_loss: 1.1751 - val_accuracy: 0.5536\n",
      "Epoch 45/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2566 - accuracy: 0.5195 - val_loss: 1.1521 - val_accuracy: 0.5598\n",
      "Epoch 46/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.2559 - accuracy: 0.5219 - val_loss: 1.1666 - val_accuracy: 0.5604\n",
      "Epoch 47/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.2480 - accuracy: 0.5218 - val_loss: 1.1657 - val_accuracy: 0.5604\n",
      "Epoch 48/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2418 - accuracy: 0.5285 - val_loss: 1.1676 - val_accuracy: 0.5632\n",
      "Epoch 49/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2315 - accuracy: 0.5289 - val_loss: 1.2036 - val_accuracy: 0.5563\n",
      "Epoch 50/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.2266 - accuracy: 0.5361 - val_loss: 1.1553 - val_accuracy: 0.5681\n",
      "Epoch 51/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2257 - accuracy: 0.5350 - val_loss: 1.1301 - val_accuracy: 0.5799\n",
      "Epoch 52/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.2158 - accuracy: 0.5350 - val_loss: 1.1256 - val_accuracy: 0.5762\n",
      "Epoch 53/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.2200 - accuracy: 0.5385 - val_loss: 1.1283 - val_accuracy: 0.5796\n",
      "Epoch 54/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2070 - accuracy: 0.5420 - val_loss: 1.1473 - val_accuracy: 0.5681\n",
      "Epoch 55/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2101 - accuracy: 0.5416 - val_loss: 1.0991 - val_accuracy: 0.5870\n",
      "Epoch 56/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2057 - accuracy: 0.5419 - val_loss: 1.1186 - val_accuracy: 0.5848\n",
      "Epoch 57/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1984 - accuracy: 0.5454 - val_loss: 1.1267 - val_accuracy: 0.5768\n",
      "Epoch 58/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.2001 - accuracy: 0.5468 - val_loss: 1.1066 - val_accuracy: 0.5802\n",
      "Epoch 59/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1862 - accuracy: 0.5484 - val_loss: 1.1030 - val_accuracy: 0.5814\n",
      "Epoch 60/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1842 - accuracy: 0.5510 - val_loss: 1.1130 - val_accuracy: 0.5789\n",
      "Epoch 61/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1823 - accuracy: 0.5482 - val_loss: 1.0813 - val_accuracy: 0.5854\n",
      "Epoch 62/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1785 - accuracy: 0.5544 - val_loss: 1.0758 - val_accuracy: 0.5941\n",
      "Epoch 63/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1683 - accuracy: 0.5582 - val_loss: 1.1239 - val_accuracy: 0.5864\n",
      "Epoch 64/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1769 - accuracy: 0.5559 - val_loss: 1.0990 - val_accuracy: 0.5854\n",
      "Epoch 65/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1644 - accuracy: 0.5589 - val_loss: 1.1136 - val_accuracy: 0.5796\n",
      "Epoch 66/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1648 - accuracy: 0.5610 - val_loss: 1.0882 - val_accuracy: 0.5901\n",
      "Epoch 67/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1611 - accuracy: 0.5606 - val_loss: 1.0847 - val_accuracy: 0.5851\n",
      "Epoch 68/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1629 - accuracy: 0.5631 - val_loss: 1.0584 - val_accuracy: 0.5929\n",
      "Epoch 69/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1514 - accuracy: 0.5683 - val_loss: 1.1051 - val_accuracy: 0.5842\n",
      "Epoch 70/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1455 - accuracy: 0.5673 - val_loss: 1.0481 - val_accuracy: 0.6040\n",
      "Epoch 71/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1473 - accuracy: 0.5658 - val_loss: 1.0586 - val_accuracy: 0.6043\n",
      "Epoch 72/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1450 - accuracy: 0.5678 - val_loss: 1.0656 - val_accuracy: 0.5907\n",
      "Epoch 73/150\n",
      "909/909 [==============================] - 17s 18ms/step - loss: 1.1404 - accuracy: 0.5685 - val_loss: 1.0476 - val_accuracy: 0.5963\n",
      "Epoch 74/150\n",
      "909/909 [==============================] - 19s 21ms/step - loss: 1.1327 - accuracy: 0.5728 - val_loss: 1.0703 - val_accuracy: 0.6000\n",
      "Epoch 75/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1343 - accuracy: 0.5703 - val_loss: 1.0665 - val_accuracy: 0.5938\n",
      "Epoch 76/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1286 - accuracy: 0.5737 - val_loss: 1.0744 - val_accuracy: 0.5950\n",
      "Epoch 77/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1271 - accuracy: 0.5755 - val_loss: 1.0644 - val_accuracy: 0.5947\n",
      "Epoch 78/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1333 - accuracy: 0.5734 - val_loss: 1.1000 - val_accuracy: 0.5926\n",
      "Epoch 79/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1204 - accuracy: 0.5781 - val_loss: 1.0396 - val_accuracy: 0.6142\n",
      "Epoch 80/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1196 - accuracy: 0.5752 - val_loss: 1.0565 - val_accuracy: 0.6056\n",
      "Epoch 81/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1160 - accuracy: 0.5798 - val_loss: 1.0667 - val_accuracy: 0.6000\n",
      "Epoch 82/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.1180 - accuracy: 0.5786 - val_loss: 1.0586 - val_accuracy: 0.6031\n",
      "Epoch 83/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.1161 - accuracy: 0.5764 - val_loss: 1.0499 - val_accuracy: 0.5981\n",
      "Epoch 84/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1195 - accuracy: 0.5800 - val_loss: 1.0630 - val_accuracy: 0.6006\n",
      "Epoch 85/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1110 - accuracy: 0.5839 - val_loss: 1.0401 - val_accuracy: 0.6102\n",
      "Epoch 86/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1039 - accuracy: 0.5822 - val_loss: 1.0853 - val_accuracy: 0.5920\n",
      "Epoch 87/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.1026 - accuracy: 0.5848 - val_loss: 1.0857 - val_accuracy: 0.5944\n",
      "Epoch 88/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.0997 - accuracy: 0.5887 - val_loss: 1.0443 - val_accuracy: 0.6062\n",
      "Epoch 89/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.1073 - accuracy: 0.5828 - val_loss: 1.0354 - val_accuracy: 0.6102\n",
      "Epoch 90/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.0979 - accuracy: 0.5893 - val_loss: 1.0293 - val_accuracy: 0.6062\n",
      "Epoch 91/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.0994 - accuracy: 0.5889 - val_loss: 1.0340 - val_accuracy: 0.6139\n",
      "Epoch 92/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0970 - accuracy: 0.5868 - val_loss: 1.0207 - val_accuracy: 0.6139\n",
      "Epoch 93/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0964 - accuracy: 0.5851 - val_loss: 1.0468 - val_accuracy: 0.6028\n",
      "Epoch 94/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0871 - accuracy: 0.5900 - val_loss: 1.0429 - val_accuracy: 0.6118\n",
      "Epoch 95/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.0930 - accuracy: 0.5884 - val_loss: 1.0430 - val_accuracy: 0.6071\n",
      "Epoch 96/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0822 - accuracy: 0.5924 - val_loss: 1.0127 - val_accuracy: 0.6173\n",
      "Epoch 97/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0889 - accuracy: 0.5929 - val_loss: 1.0255 - val_accuracy: 0.6080\n",
      "Epoch 98/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0822 - accuracy: 0.5952 - val_loss: 1.0395 - val_accuracy: 0.6152\n",
      "Epoch 99/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0785 - accuracy: 0.5929 - val_loss: 1.0296 - val_accuracy: 0.6152\n",
      "Epoch 100/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0838 - accuracy: 0.5913 - val_loss: 1.0289 - val_accuracy: 0.6167\n",
      "Epoch 101/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0748 - accuracy: 0.5994 - val_loss: 1.0178 - val_accuracy: 0.6152\n",
      "Epoch 102/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0754 - accuracy: 0.5971 - val_loss: 1.0138 - val_accuracy: 0.6139\n",
      "Epoch 103/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0738 - accuracy: 0.5973 - val_loss: 1.0089 - val_accuracy: 0.6173\n",
      "Epoch 104/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0668 - accuracy: 0.6001 - val_loss: 1.0415 - val_accuracy: 0.6149\n",
      "Epoch 105/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0718 - accuracy: 0.5991 - val_loss: 1.0323 - val_accuracy: 0.6149\n",
      "Epoch 106/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0663 - accuracy: 0.5967 - val_loss: 1.0093 - val_accuracy: 0.6155\n",
      "Epoch 107/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0681 - accuracy: 0.6011 - val_loss: 1.0466 - val_accuracy: 0.6111\n",
      "Epoch 108/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0665 - accuracy: 0.5994 - val_loss: 1.0401 - val_accuracy: 0.6019\n",
      "Epoch 109/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.0633 - accuracy: 0.5983 - val_loss: 1.0121 - val_accuracy: 0.6170\n",
      "Epoch 110/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.0664 - accuracy: 0.6030 - val_loss: 1.0229 - val_accuracy: 0.6115\n",
      "Epoch 111/150\n",
      "909/909 [==============================] - 17s 19ms/step - loss: 1.0646 - accuracy: 0.6000 - val_loss: 1.0020 - val_accuracy: 0.6164\n",
      "Epoch 112/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0593 - accuracy: 0.6054 - val_loss: 1.0187 - val_accuracy: 0.6176\n",
      "Epoch 113/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0561 - accuracy: 0.6067 - val_loss: 1.0155 - val_accuracy: 0.6198\n",
      "Epoch 114/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0605 - accuracy: 0.6051 - val_loss: 1.0171 - val_accuracy: 0.6105\n",
      "Epoch 115/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0501 - accuracy: 0.6082 - val_loss: 1.0357 - val_accuracy: 0.6062\n",
      "Epoch 116/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0546 - accuracy: 0.6048 - val_loss: 1.0271 - val_accuracy: 0.6164\n",
      "Epoch 117/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0492 - accuracy: 0.6079 - val_loss: 1.0317 - val_accuracy: 0.6198\n",
      "Epoch 118/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0546 - accuracy: 0.6081 - val_loss: 1.0078 - val_accuracy: 0.6226\n",
      "Epoch 119/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0449 - accuracy: 0.6091 - val_loss: 1.0330 - val_accuracy: 0.6121\n",
      "Epoch 120/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0439 - accuracy: 0.6064 - val_loss: 0.9932 - val_accuracy: 0.6254\n",
      "Epoch 121/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0445 - accuracy: 0.6109 - val_loss: 0.9987 - val_accuracy: 0.6285\n",
      "Epoch 122/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0494 - accuracy: 0.6090 - val_loss: 1.0099 - val_accuracy: 0.6229\n",
      "Epoch 123/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0397 - accuracy: 0.6093 - val_loss: 1.0346 - val_accuracy: 0.6248\n",
      "Epoch 124/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0387 - accuracy: 0.6113 - val_loss: 0.9876 - val_accuracy: 0.6294\n",
      "Epoch 125/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0414 - accuracy: 0.6111 - val_loss: 1.0299 - val_accuracy: 0.6220\n",
      "Epoch 126/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0439 - accuracy: 0.6113 - val_loss: 1.0271 - val_accuracy: 0.6241\n",
      "Epoch 127/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0426 - accuracy: 0.6097 - val_loss: 1.0079 - val_accuracy: 0.6207\n",
      "Epoch 128/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0345 - accuracy: 0.6149 - val_loss: 1.0037 - val_accuracy: 0.6235\n",
      "Epoch 129/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0340 - accuracy: 0.6138 - val_loss: 0.9984 - val_accuracy: 0.6344\n",
      "Epoch 130/150\n",
      "909/909 [==============================] - 18s 19ms/step - loss: 1.0354 - accuracy: 0.6114 - val_loss: 1.0068 - val_accuracy: 0.6214\n",
      "Epoch 131/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0303 - accuracy: 0.6141 - val_loss: 1.0052 - val_accuracy: 0.6279\n",
      "Epoch 132/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0263 - accuracy: 0.6162 - val_loss: 1.0095 - val_accuracy: 0.6195\n",
      "Epoch 133/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0282 - accuracy: 0.6160 - val_loss: 1.0272 - val_accuracy: 0.6229\n",
      "Epoch 134/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0352 - accuracy: 0.6127 - val_loss: 1.0263 - val_accuracy: 0.6263\n",
      "Epoch 135/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0264 - accuracy: 0.6139 - val_loss: 0.9956 - val_accuracy: 0.6226\n",
      "Epoch 136/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0312 - accuracy: 0.6123 - val_loss: 0.9819 - val_accuracy: 0.6341\n",
      "Epoch 137/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0216 - accuracy: 0.6190 - val_loss: 1.0023 - val_accuracy: 0.6176\n",
      "Epoch 138/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0269 - accuracy: 0.6122 - val_loss: 0.9806 - val_accuracy: 0.6381\n",
      "Epoch 139/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0301 - accuracy: 0.6158 - val_loss: 0.9933 - val_accuracy: 0.6248\n",
      "Epoch 140/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0219 - accuracy: 0.6156 - val_loss: 1.0228 - val_accuracy: 0.6130\n",
      "Epoch 141/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0218 - accuracy: 0.6168 - val_loss: 0.9926 - val_accuracy: 0.6285\n",
      "Epoch 142/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0147 - accuracy: 0.6198 - val_loss: 0.9944 - val_accuracy: 0.6173\n",
      "Epoch 143/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0261 - accuracy: 0.6171 - val_loss: 1.0124 - val_accuracy: 0.6241\n",
      "Epoch 144/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0150 - accuracy: 0.6223 - val_loss: 1.0061 - val_accuracy: 0.6260\n",
      "Epoch 145/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0226 - accuracy: 0.6198 - val_loss: 0.9823 - val_accuracy: 0.6372\n",
      "Epoch 146/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0135 - accuracy: 0.6226 - val_loss: 0.9890 - val_accuracy: 0.6300\n",
      "Epoch 147/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0172 - accuracy: 0.6245 - val_loss: 1.0030 - val_accuracy: 0.6130\n",
      "Epoch 148/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0059 - accuracy: 0.6251 - val_loss: 0.9865 - val_accuracy: 0.6337\n",
      "Epoch 149/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0128 - accuracy: 0.6215 - val_loss: 1.0034 - val_accuracy: 0.6214\n",
      "Epoch 150/150\n",
      "909/909 [==============================] - 18s 20ms/step - loss: 1.0122 - accuracy: 0.6224 - val_loss: 0.9928 - val_accuracy: 0.6269\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compiling model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Specifying parameters for Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=40,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,\n",
    "    zoom_range = 0.05)  # zoom images in range [1 - zoom_range, 1+ zoom_range]\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train,batch_size=32), epochs=150, validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmjOWjjVK6JX",
    "outputId": "293f667e-eae9-4d03-e8fd-2adb48f0c25e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"/content/drive/MyDrive/Emotion_detection/model.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "model.save_weights(\"/content/drive/MyDrive/Emotion_detection/model.hdf5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5vEDpIK9334"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Emotion_detection_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
